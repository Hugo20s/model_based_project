#--------initialize variables
n <- nrow(data); p <- ncol(data)
if (type_init == "kmeans"){
parameters <- init_kmeans(data, K)
}
if ((type_init == "random") || (type_init == "small"))  {
parameters <- init_random(data, K)
}
#Loop
i <- 2
log_likelihood <- numeric(0)
log_likelihood[1] <- -Inf
while (i > 0) {
tk <- etape_E(data, K, parameters)
for (k in 1:K){
print(sum(tk[,k]))
}
parameters <- etape_M(data, K, tk)
pk <- parameters$pk
moyenne <- parameters$moyenne
variance <- parameters$variance
LL <- sum(log(apply(sapply(lapply(1:K,
function(k) pk[k] * emdbook::dmvnorm(data, moyenne[k,],
variance[,,k])), cbind), 1, sum)))
log_likelihood[i] <- LL
if (LL < log_likelihood[i-1]){
set_inf <- TRUE
print(log_likelihood[i] - log_likelihood[i-1])
}
if (abs(log_likelihood[i] - log_likelihood[i-1]) < epsilon){
y_pred <- apply(tk, 1, which.max)
if (set_inf){
print("KO")
}
print(i)
print(abs(log_likelihood[i] - log_likelihood[i-1]))
return(list(log_likelihood = log_likelihood[-1], y_pred = y_pred))
}
if ((type_init == "small") && (i == 5)) {
return( clustering(data, K, epsilon, "", parameters ) )
}
i <- i + 1
}
}
K <- 3
split <- sample(1:150, 50)
y <- iris[-split, 5]
data <- iris[-split, -5]
epsilon <- 10^-6
data <- as.matrix(data)
res <- clustering(data, K, epsilon, "small")
res <- clustering(data, K, epsilon, "small")
res <- clustering(data, K, epsilon, "small")
table(res$y_pred, y)
res <- clustering(data, K, epsilon, "small")
res <- clustering(data, K, epsilon, "small")
res <- clustering(data, K, epsilon, "small")
for (i in 1:100){
res <- clustering(data, K, epsilon, "small")
print(typeof(res))
if (typeof(res) == "list"){
print(res$log_likelihood[length(res$log_likelihood)])
}
print("-----")
}
etape_E <- function(data, K, parameters){
pk <- parameters$pk
moyenne <- parameters$moyenne
variance <- parameters$variance
tk <- matrix(0,  nrow(data), K)
for (k in 1:K){
tk[, k] <- pk[k]* emdbook::dmvnorm(data, moyenne[k,], variance[,,k])
}
tk <- tk/apply(tk, 1, sum)
for (k in 1:K){
if (sum(tk[,k]) == 0){
print(variance)
print(moyenne)
}
}
return (tk)
}
etape_M <- function(data, K, tk){
N <- nrow(data)
f <- ncol(data)
nk <- colSums(tk)
pk <- nk/N
moyenne  <- fun_moyenne_vec(data, tk,nk,K, N,  f)
variance  <- fun_variance_pkg(data, tk, nk, K, N, f, moyenne)
return (list(pk=pk, moyenne=moyenne, variance=variance))
}
clustering <- function(data, K, epsilon, type_init = "kmeans", parameters = 0){
set_inf <- FALSE
#--------initialize variables
n <- nrow(data); p <- ncol(data)
if (type_init == "kmeans"){
parameters <- init_kmeans(data, K)
}
if ((type_init == "random") || (type_init == "small"))  {
parameters <- init_random(data, K)
}
#Loop
i <- 2
log_likelihood <- numeric(0)
log_likelihood[1] <- -Inf
while (i > 0) {
tk <- etape_E(data, K, parameters)
parameters <- etape_M(data, K, tk)
pk <- parameters$pk
moyenne <- parameters$moyenne
variance <- parameters$variance
LL <- sum(log(apply(sapply(lapply(1:K,
function(k) pk[k] * emdbook::dmvnorm(data, moyenne[k,],
variance[,,k])), cbind), 1, sum)))
log_likelihood[i] <- LL
if (LL < log_likelihood[i-1]){
set_inf <- TRUE
print(log_likelihood[i] - log_likelihood[i-1])
}
if (abs(log_likelihood[i] - log_likelihood[i-1]) < epsilon){
y_pred <- apply(tk, 1, which.max)
if (set_inf){
print("KO")
}
print(i)
print(abs(log_likelihood[i] - log_likelihood[i-1]))
return(list(log_likelihood = log_likelihood[-1], y_pred = y_pred))
}
if ((type_init == "small") && (i == 5)) {
return( clustering(data, K, epsilon, "", parameters ) )
}
i <- i + 1
}
}
K <- 3
split <- sample(1:150, 50)
y <- iris[-split, 5]
data <- iris[-split, -5]
epsilon <- 10^-6
data <- as.matrix(data)
res <- clustering(data, K, epsilon, "small")
table(res$y_pred, y)
for (i in 1:100){
res <- clustering(data, K, epsilon, "small")
print(typeof(res))
if (typeof(res) == "list"){
print(res$log_likelihood[length(res$log_likelihood)])
}
print("-----")
}
etape_E <- function(data, K, parameters){
pk <- parameters$pk
moyenne <- parameters$moyenne
variance <- parameters$variance
tk <- matrix(0,  nrow(data), K)
for (k in 1:K){
tk[, k] <- pk[k]* emdbook::dmvnorm(data, moyenne[k,], variance[,,k])
}
tk <- tk/apply(tk, 1, sum)
for (k in 1:K){
if (sum(tk[,k]) == 0){
print(sum(tk[,k]))
print(variance)
print(moyenne)
}
}
return (tk)
}
etape_M <- function(data, K, tk){
N <- nrow(data)
f <- ncol(data)
nk <- colSums(tk)
pk <- nk/N
moyenne  <- fun_moyenne_vec(data, tk,nk,K, N,  f)
variance  <- fun_variance_pkg(data, tk, nk, K, N, f, moyenne)
return (list(pk=pk, moyenne=moyenne, variance=variance))
}
clustering <- function(data, K, epsilon, type_init = "kmeans", parameters = 0){
set_inf <- FALSE
#--------initialize variables
n <- nrow(data); p <- ncol(data)
if (type_init == "kmeans"){
parameters <- init_kmeans(data, K)
}
if ((type_init == "random") || (type_init == "small"))  {
parameters <- init_random(data, K)
}
#Loop
i <- 2
log_likelihood <- numeric(0)
log_likelihood[1] <- -Inf
while (i > 0) {
tk <- etape_E(data, K, parameters)
parameters <- etape_M(data, K, tk)
pk <- parameters$pk
moyenne <- parameters$moyenne
variance <- parameters$variance
LL <- sum(log(apply(sapply(lapply(1:K,
function(k) pk[k] * emdbook::dmvnorm(data, moyenne[k,],
variance[,,k])), cbind), 1, sum)))
log_likelihood[i] <- LL
if (LL < log_likelihood[i-1]){
set_inf <- TRUE
print(log_likelihood[i] - log_likelihood[i-1])
}
if (abs(log_likelihood[i] - log_likelihood[i-1]) < epsilon){
y_pred <- apply(tk, 1, which.max)
if (set_inf){
print("KO")
}
print(i)
print(abs(log_likelihood[i] - log_likelihood[i-1]))
return(list(log_likelihood = log_likelihood[-1], y_pred = y_pred))
}
if ((type_init == "small") && (i == 5)) {
return( clustering(data, K, epsilon, "", parameters ) )
}
i <- i + 1
}
}
K <- 3
split <- sample(1:150, 50)
y <- iris[-split, 5]
data <- iris[-split, -5]
epsilon <- 10^-6
data <- as.matrix(data)
res <- clustering(data, K, epsilon, "small")
table(res$y_pred, y)
plot(res$log_likelihood)
plot(res$y_pred)
c <- 0
for (i in 1:100){
res <- clustering(data, K, epsilon, "small")
print(typeof(res))
if (typeof(res) == "list"){
print(res$log_likelihood[length(res$log_likelihood)])
}
print("-----")
}
clustering <- function(data, K, epsilon, type_init = "kmeans", parameters = 0){
set_inf <- FALSE
#--------initialize variables
n <- nrow(data); p <- ncol(data)
if (type_init == "kmeans"){
parameters <- init_kmeans(data, K)
}
if ((type_init == "random") || (type_init == "small"))  {
parameters <- init_random(data, K)
}
#Loop
i <- 2
log_likelihood <- numeric(0)
log_likelihood[1] <- -Inf
while (i > 0) {
tk <- etape_E(data, K, parameters)
parameters <- etape_M(data, K, tk)
pk <- parameters$pk
moyenne <- parameters$moyenne
variance <- parameters$variance
LL <- sum(log(apply(sapply(lapply(1:K,
function(k) pk[k] * emdbook::dmvnorm(data, moyenne[k,],
variance[,,k])), cbind), 1, sum)))
log_likelihood[i] <- LL
if (LL < log_likelihood[i-1]){
set_inf <- TRUE
print(log_likelihood[i] - log_likelihood[i-1])
}
if (abs(log_likelihood[i] - log_likelihood[i-1]) < epsilon){
y_pred <- apply(tk, 1, which.max)
if (set_inf){
print("___________________________________________________________KO")
}
print(i)
print(abs(log_likelihood[i] - log_likelihood[i-1]))
return(list(log_likelihood = log_likelihood[-1], y_pred = y_pred))
}
if ((type_init == "small") && (i == 5)) {
return( clustering(data, K, epsilon, "", parameters ) )
}
i <- i + 1
}
}
K <- 3
split <- sample(1:150, 50)
y <- iris[-split, 5]
data <- iris[-split, -5]
epsilon <- 10^-6
data <- as.matrix(data)
plot(res$log_likelihood)
plot(res$y_pred)
c <- 0
for (i in 1:100){
res <- clustering(data, K, epsilon, "small")
print(typeof(res))
if (typeof(res) == "list"){
print(res$log_likelihood[length(res$log_likelihood)])
}
print("-----")
}
clustering <- function(data, K, epsilon, type_init = "kmeans", parameters = 0){
set_inf <- FALSE
#--------initialize variables
n <- nrow(data); p <- ncol(data)
if (type_init == "kmeans"){
parameters <- init_kmeans(data, K)
}
if ((type_init == "random") || (type_init == "small"))  {
parameters <- init_random(data, K)
}
#Loop
i <- 2
log_likelihood <- numeric(0)
log_likelihood[1] <- -Inf
while (i > 0) {
tk <- etape_E(data, K, parameters)
parameters <- etape_M(data, K, tk)
pk <- parameters$pk
moyenne <- parameters$moyenne
variance <- parameters$variance
LL <- sum(log(apply(sapply(lapply(1:K,
function(k) pk[k] * emdbook::dmvnorm(data, moyenne[k,],
variance[,,k])), cbind), 1, sum)))
log_likelihood[i] <- LL
if (LL < log_likelihood[i-1]){
set_inf <- TRUE
print("------ debug KO")
print("tk")
print(tk)
print("sum tk")
print(colSum(tk))
print("pk")
print(pk)
print("moyenne")
print(moyenne)
print("variable")
print(variable)
}
if (abs(log_likelihood[i] - log_likelihood[i-1]) < epsilon){
y_pred <- apply(tk, 1, which.max)
if (set_inf){
print("___________________________________________________________KO")
}
print(i)
print(abs(log_likelihood[i] - log_likelihood[i-1]))
return(list(log_likelihood = log_likelihood[-1], y_pred = y_pred))
}
if ((type_init == "small") && (i == 5)) {
return( clustering(data, K, epsilon, "", parameters ) )
}
i <- i + 1
}
}
K <- 3
split <- sample(1:150, 50)
y <- iris[-split, 5]
data <- iris[-split, -5]
epsilon <- 10^-6
data <- as.matrix(data)
res <- clustering(data, K, epsilon, "small")
table(res$y_pred, y)
plot(res$log_likelihood)
plot(res$log_likelihood)
plot(res$y_pred)
c <- 0
for (i in 1:100){
res <- clustering(data, K, epsilon, "small")
print(typeof(res))
if (typeof(res) == "list"){
print(res$log_likelihood[length(res$log_likelihood)])
}
print("-----")
}
clustering <- function(data, K, epsilon, type_init = "kmeans", parameters = 0){
set_inf <- FALSE
#--------initialize variables
n <- nrow(data); p <- ncol(data)
if (type_init == "kmeans"){
parameters <- init_kmeans(data, K)
}
if ((type_init == "random") || (type_init == "small"))  {
parameters <- init_random(data, K)
}
#Loop
i <- 2
log_likelihood <- numeric(0)
log_likelihood[1] <- -Inf
while (i > 0) {
tk <- etape_E(data, K, parameters)
parameters <- etape_M(data, K, tk)
pk <- parameters$pk
moyenne <- parameters$moyenne
variance <- parameters$variance
LL <- sum(log(apply(sapply(lapply(1:K,
function(k) pk[k] * emdbook::dmvnorm(data, moyenne[k,],
variance[,,k])), cbind), 1, sum)))
log_likelihood[i] <- LL
if (LL < log_likelihood[i-1]){
set_inf <- TRUE
print("------ debug KO")
print("tk")
print(tk)
print("sum tk")
print(colSums(tk))
print("pk")
print(pk)
print("moyenne")
print(moyenne)
print("variable")
print(variable)
}
if (abs(log_likelihood[i] - log_likelihood[i-1]) < epsilon){
y_pred <- apply(tk, 1, which.max)
if (set_inf){
print("___________________________________________________________KO")
}
print(i)
print(abs(log_likelihood[i] - log_likelihood[i-1]))
return(list(log_likelihood = log_likelihood[-1], y_pred = y_pred))
}
if ((type_init == "small") && (i == 5)) {
return( clustering(data, K, epsilon, "", parameters ) )
}
i <- i + 1
}
}
K <- 3
split <- sample(1:150, 50)
y <- iris[-split, 5]
data <- iris[-split, -5]
epsilon <- 10^-6
data <- as.matrix(data)
res <- clustering(data, K, epsilon, "small")
for (i in 1:100){
res <- clustering(data, K, epsilon, "small")
print(typeof(res))
if (typeof(res) == "list"){
print(res$log_likelihood[length(res$log_likelihood)])
}
print("-----")
}
clustering <- function(data, K, epsilon, type_init = "kmeans", parameters = 0){
set_inf <- FALSE
#--------initialize variables
n <- nrow(data); p <- ncol(data)
if (type_init == "kmeans"){
parameters <- init_kmeans(data, K)
}
if ((type_init == "random") || (type_init == "small"))  {
parameters <- init_random(data, K)
}
#Loop
i <- 2
log_likelihood <- numeric(0)
log_likelihood[1] <- -Inf
while (i > 0) {
tk <- etape_E(data, K, parameters)
parameters <- etape_M(data, K, tk)
pk <- parameters$pk
moyenne <- parameters$moyenne
variance <- parameters$variance
LL <- sum(log(apply(sapply(lapply(1:K,
function(k) pk[k] * emdbook::dmvnorm(data, moyenne[k,],
variance[,,k])), cbind), 1, sum)))
log_likelihood[i] <- LL
if (LL < log_likelihood[i-1]){
set_inf <- TRUE
print("------ debug KO")
print("tk")
print(tk)
print("sum tk")
print(colSums(tk))
print("pk")
print(pk)
print("moyenne")
print(moyenne)
print("variance")
print(variance)
}
if (abs(log_likelihood[i] - log_likelihood[i-1]) < epsilon){
y_pred <- apply(tk, 1, which.max)
if (set_inf){
print("___________________________________________________________KO")
}
print(i)
print(abs(log_likelihood[i] - log_likelihood[i-1]))
return(list(log_likelihood = log_likelihood[-1], y_pred = y_pred))
}
if ((type_init == "small") && (i == 5)) {
return( clustering(data, K, epsilon, "", parameters ) )
}
i <- i + 1
}
}
K <- 3
split <- sample(1:150, 50)
y <- iris[-split, 5]
data <- iris[-split, -5]
epsilon <- 10^-6
data <- as.matrix(data)
res <- clustering(data, K, epsilon, "small")
table(res$y_pred, y)
plot(res$log_likelihood)
plot(res$y_pred)
c <- 0
for (i in 1:100){
res <- clustering(data, K, epsilon, "small")
print(typeof(res))
if (typeof(res) == "list"){
print(res$log_likelihood[length(res$log_likelihood)])
}
print("-----")
}
